{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c09942d",
   "metadata": {},
   "source": [
    "# Homework 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb8555",
   "metadata": {},
   "source": [
    "## By Team VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7831a62a",
   "metadata": {},
   "source": [
    "### Document classification with the NLTK Classfiyer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3d61e",
   "metadata": {},
   "source": [
    "For this week's homework, we created a spam classiyer with NLTK. We will use the [SMS Spam data collection](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download) for our spam detection purposes. The reason we went with the SMS dataset as there is a rise in mobile phishing. There is a delay in identification of these types of phishing cases as mobile providers fall behind in the text analysis of messages compared to the hundreds of mobile apps for phone type phishing. This delay could be from a privacy policy with the consumer or the developement of these softwares have not reached the final testing stages. Let's simulate what this detection might look like below!\n",
    "\n",
    "The dataset imported has two useful columns: Ham/spam and its string. We wanted to mirror the data frame given in the Spambase data set for features our classiyer can use. These transfomation included some word frequencies with the forumlas given by [UCI](https://archive.ics.uci.edu/ml/datasets/spambaseet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98d04aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from numpy import mean\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "\n",
    "\n",
    "data=pd.read_csv('spam.csv', header=0,names=['Spam_Value', 'Str'],usecols=['Spam_Value','Str'],encoding=\"ISO-8859-1\")  \n",
    "\n",
    "# randomize the data\n",
    "#data = shuffle(data)\n",
    "\n",
    "# split the data into a training set (4572 observations) and a test set (1000 observations)\n",
    "#test_data = data.iloc[4572:]\n",
    "#data = data.iloc[0:4572]\n",
    "\n",
    "#flip order of the data frame to use classifyer\n",
    "flip_df=pd.DataFrame().assign(Str=data['Str'],Spam_Value=data['Spam_Value'])\n",
    "#print(flip_df)\n",
    "\n",
    "\n",
    "#collect word counts to calculate frequencies| Word counts| Avgs-> Make a frequnecy chart \n",
    "d_stats=pd.DataFrame()\n",
    "d_stats['spam_ham']=data['Str']\n",
    "\n",
    "#Find the total word count of the text\n",
    "d_stats['Word_count']=data['Str'].str.split().str.len()\n",
    "d_stats['Char_count']=data['Str'].str.len()\n",
    "\n",
    "#Find all the capital words in the string- metric by UCI\n",
    "d_stats['capital_run_length_total']=data['Str'].str.count(\"[A-Z]{2,}\")\n",
    "#d_stats.loc[5:15,]\n",
    "\n",
    "#Find longest Capital word in the text\n",
    "def longest_Cap(w):\n",
    "    l=w.str.findall(\"[A-Z]{2,}\")\n",
    "    n=[0 if not n else len(max(n,key=len)) for n in l]\n",
    "    return n\n",
    "\n",
    "d_stats[\"capital_run_length_longest\"]=longest_Cap(data['Str'])\n",
    "\n",
    "#Find average capital words in a text | inspo of list avg from geek4geek's Average String length in list\n",
    "def avg_Cap(w):\n",
    "    l=w.str.findall(\"[A-Z]{2,}\")\n",
    "    n=[0 if not n else sum(map(len, n))/float(len(n)) for n in l]\n",
    "    return n\n",
    "\n",
    "d_stats[\"capital_run_length_average\"]=avg_Cap(data['Str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d2d02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Section for words frequenices of our interest, Combo of UCI's word freq and ones we see in spam texts\n",
    "d_stats['freq_order']=data['Str'].str.count(\"order\",flags=re.I)\n",
    "d_stats['freq_receive']=data['Str'].str.count(\"receieve\",flags=re.I)\n",
    "d_stats['freq_will']=data['Str'].str.count(\"will\",flags=re.I)\n",
    "d_stats['freq_over']=data['Str'].str.count(\"over\",flags=re.I)\n",
    "d_stats['freq_you']=data['Str'].str.count(\"you\",flags=re.I)\n",
    "d_stats['freq_your']=data['Str'].str.count(\"your\",flags=re.I)\n",
    "d_stats['freq_credit']=data['Str'].str.count(\"credit\",flags=re.I)\n",
    "d_stats['freq_order']=data['Str'].str.count(\"order\",flags=re.I)\n",
    "d_stats['freq_free']=data['Str'].str.count(\"free\",flags=re.I)\n",
    "d_stats['freq_alert']=data['Str'].str.count(\"alert\",flags=re.I)\n",
    "d_stats['freq_urgent']=data['Str'].str.count(\"urgent\",flags=re.I)\n",
    "d_stats['freq_tried']=data['Str'].str.count(\"tried\",flags=re.I)\n",
    "d_stats['freq_txt']=data['Str'].str.count(\"txt\",flags=re.I)\n",
    "d_stats['freq_(']=data['Str'].str.count(\"\\(\")\n",
    "d_stats['freq_!']=data['Str'].str.count(\"!\")\n",
    "d_stats['freq_[']=data['Str'].str.count(\"\\[\")\n",
    "d_stats['freq_$']=data['Str'].str.count(\"\\$\")\n",
    "d_stats['freq_#']=data['Str'].str.count(\"#\")\n",
    "\n",
    "d_stats['freq_order']=(100*d_stats['freq_order'])/d_stats['Word_count']\n",
    "d_stats['freq_receive']=(100*d_stats['freq_receive'])/d_stats['Word_count']\n",
    "d_stats['freq_will']=(100*d_stats['freq_will'])/d_stats['Word_count']\n",
    "d_stats['freq_over']=(100*d_stats['freq_over'])/d_stats['Word_count']\n",
    "d_stats['freq_you']=(100*d_stats['freq_you'])/d_stats['Word_count']\n",
    "d_stats['freq_your']=(100*d_stats['freq_your'])/d_stats['Word_count']\n",
    "d_stats['freq_credit']=(100*d_stats['freq_credit'])/d_stats['Word_count']\n",
    "d_stats['freq_order']=(100*d_stats['freq_order'])/d_stats['Word_count']\n",
    "d_stats['freq_free']=(100*d_stats['freq_free'])/d_stats['Word_count']\n",
    "d_stats['freq_alert']=(100*d_stats['freq_alert'])/d_stats['Word_count']\n",
    "d_stats['freq_urgent']=(100*d_stats['freq_urgent'])/d_stats['Word_count']\n",
    "d_stats['freq_tried']=(100*d_stats['freq_tried'])/d_stats['Word_count']\n",
    "d_stats['freq_txt']=(100*d_stats['freq_txt'])/d_stats['Word_count']\n",
    "d_stats['freq_(']=(100*d_stats['freq_('])/d_stats['Char_count']\n",
    "d_stats['freq_!']=(100*d_stats['freq_!'])/d_stats['Char_count']\n",
    "d_stats['freq_[']=(100*d_stats['freq_['])/d_stats['Char_count']\n",
    "d_stats['freq_$']=(100*d_stats['freq_$'])/d_stats['Char_count']\n",
    "d_stats['freq_#']=(100*d_stats['freq_#'])/d_stats['Char_count']\n",
    "\n",
    "#display(d_stats[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715340b8",
   "metadata": {},
   "source": [
    "### Setting up the classfiyer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11accb",
   "metadata": {},
   "source": [
    "Let's set up the classifyer. For our features, we decided to host all the possible features in a seperate data frame. It allowed us to create more granular feature list without the extra space within all the functions. The text message was used as our key to D_stats, which carried all possible metrics for our features list. We handled any popular text with the .values[0], as it will bring back the first value from the text message search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5b6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating features list\n",
    "\n",
    "#Set up our features functions\n",
    "def base_case(txt):\n",
    "    return {'throw': 1 }\n",
    "\n",
    "def freq_feautures(txt):\n",
    "    features={}\n",
    "    features['freq_order'] = d_stats.loc[d_stats.spam_ham==txt,'freq_order'].values[0]\n",
    "    features['freq_receive']=d_stats.loc[d_stats.spam_ham==txt,'freq_receive'].values[0]\n",
    "    features['freq_will']=d_stats.loc[d_stats.spam_ham==txt,'freq_will'].values[0]\n",
    "    features['freq_over']=d_stats.loc[d_stats.spam_ham==txt,'freq_over'].values[0]\n",
    "    features['freq_you']=d_stats.loc[d_stats.spam_ham==txt,'freq_you'].values[0]\n",
    "    features['freq_your']=d_stats.loc[d_stats.spam_ham==txt,'freq_your'].values[0]\n",
    "    features['freq_credit']=d_stats.loc[d_stats.spam_ham==txt,'freq_credit'].values[0]\n",
    "    features['freq_order']=d_stats.loc[d_stats.spam_ham==txt,'freq_order'].values[0]\n",
    "    features['freq_free']=d_stats.loc[d_stats.spam_ham==txt,'freq_free'].values[0]\n",
    "    features['freq_alert']=d_stats.loc[d_stats.spam_ham==txt,'freq_alert'].values[0]\n",
    "    features['freq_urgent']=d_stats.loc[d_stats.spam_ham==txt,'freq_urgent'].values[0]\n",
    "    features['freq_tried']=d_stats.loc[d_stats.spam_ham==txt,'freq_order'].values[0]\n",
    "    features['freq_txt']=d_stats.loc[d_stats.spam_ham==txt,'freq_txt'].values[0]\n",
    "    features['freq_(']=d_stats.loc[d_stats.spam_ham==txt,'freq_('].values[0]\n",
    "    features['freq_!']=d_stats.loc[d_stats.spam_ham==txt,'freq_!'].values[0]\n",
    "    features['freq_[']=d_stats.loc[d_stats.spam_ham==txt,'freq_['].values[0]\n",
    "    features['freq_$']=d_stats.loc[d_stats.spam_ham==txt,'freq_$'].values[0]\n",
    "    features['freq_#']=d_stats.loc[d_stats.spam_ham==txt,'freq_#'].values[0]\n",
    "    return features\n",
    "def word_features(txt):\n",
    "    features={}\n",
    "    features['Word_count'] = d_stats.loc[d_stats.spam_ham==txt,'Word_count'].values[0]\n",
    "    features['Char_count'] = d_stats.loc[d_stats.spam_ham==txt,'Char_count'].values[0]\n",
    "    features['capital_run_length_total'] = d_stats.loc[d_stats.spam_ham==txt,'capital_run_length_total'].values[0]\n",
    "    features['capital_run_length_longest'] = d_stats.loc[d_stats.spam_ham==txt,'capital_run_length_longest'].values[0]\n",
    "    features['capital_run_length_average'] = d_stats.loc[d_stats.spam_ham==txt,'capital_run_length_average'].values[0]\n",
    "    return features\n",
    "\n",
    "def mix_features(txt):\n",
    "    features={}\n",
    "    features['Word_count'] = d_stats.loc[d_stats.spam_ham==txt,'Word_count'].values[0]\n",
    "    features['capital_run_length_total'] = d_stats.loc[d_stats.spam_ham==txt,'capital_run_length_total'].values[0]\n",
    "    features['freq_free']=d_stats.loc[d_stats.spam_ham==txt,'freq_free'].values[0]\n",
    "    features['freq_!']=d_stats.loc[d_stats.spam_ham==txt,'freq_!'].values[0]\n",
    "    features['freq_#']=d_stats.loc[d_stats.spam_ham==txt,'freq_#'].values[0]\n",
    "    features['capital_run_length_average'] = d_stats.loc[d_stats.spam_ham==txt,'capital_run_length_average'].values[0]\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0227b062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Then what about further plan?', 'ham')\n",
      " ('Im good! I have been thinking about you...', 'ham')\n",
      " ('They can try! They can get lost, in fact. Tee hee', 'ham')]\n"
     ]
    }
   ],
   "source": [
    "#collection of features to test\n",
    "all_features=[base_case,freq_feautures,word_features,mix_features]\n",
    "\n",
    "#randomly sort our string and sort between training and test set\n",
    "flip_df=shuffle(flip_df)\n",
    "flip_df=flip_df.to_records(index=False)\n",
    "train_names,test_names = flip_df[0:2000], flip_df[2001:4572]\n",
    "\n",
    "print(test_names[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e56f7ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results_list,\n\u001b[0;32m     19\u001b[0m                           columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     20\u001b[0m                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     21\u001b[0m                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                                    ])\n\u001b[0;32m     24\u001b[0m results_df\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m---> 25\u001b[0m ax\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m df\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,secondary_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ax\u001b[38;5;241m=\u001b[39max)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "\n",
    "# For each feature function, try to classify the test sets\n",
    "for fn in all_features:\n",
    "    train_set = [(fn(n), g) for (n,g) in train_names]\n",
    "    test_set = [(word_features(n), g) for (n,g) in test_names]\n",
    "    \n",
    "    # make a classifier from the training set\n",
    "    classifier = nltk.classify.DecisionTreeClassifier.train(train_set)\n",
    "    \n",
    "    # Print the classifier logic\n",
    "    accuracy_train = nltk.classify.accuracy(classifier, train_set)\n",
    "    accuracy_test = nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "    results_list.append([fn.__name__, accuracy_train, accuracy_test])\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list,\n",
    "                          columns=['Function', \n",
    "                                   'Training Accuracy', \n",
    "                                   'Test Accuracy',\n",
    "                                   ])\n",
    "\n",
    "results_df.head()\n",
    "ax=results_df.plot('Function','Training Accuracy')\n",
    "df.plot('Function','Test Accuracy',secondary_y=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7beb7",
   "metadata": {},
   "source": [
    "### Searching for SPAM through bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebff471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ data['Spam_Value'] == 'spam'  ]['Str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd581d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "from nltk import bigrams\n",
    "import nltk\n",
    "\n",
    "def tokenize(sentences):\n",
    "    for sent in nltk.sent_tokenize(sentences.lower()):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "              yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data[ data['Spam_Value'] == 'spam'  ]['Str'].tolist()\n",
    "all_spam = \" \".join(sentences).lower()\n",
    "words = tokenize(all_spam)\n",
    "text = nltk.Text(words)\n",
    "print(\"Collocated spam words\")\n",
    "text.collocations(15)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Use a bigram collocation finder\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "tokens = nltk.wordpunct_tokenize(all_spam)\n",
    "finder = BigramCollocationFinder.from_words(tokens)\n",
    "finder.apply_freq_filter(3)\n",
    "finder.nbest(bigram_measures.pmi, 10)\n",
    "\n",
    "print(\"bigram collocations\")\n",
    "print(sorted(finder.nbest(bigram_measures.pmi, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a3de7",
   "metadata": {},
   "source": [
    "### Takeaways"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
