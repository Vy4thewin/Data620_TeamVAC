{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcb6db3",
   "metadata": {},
   "source": [
    "# Project 3 Text analysis with NLTK Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96f4d6",
   "metadata": {},
   "source": [
    "## By Team VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8751c7",
   "metadata": {},
   "source": [
    "### Intro into Text Mining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8b6bf",
   "metadata": {},
   "source": [
    "For Project 3, We are given the tasks to improved the gender classifyer shown in Chapter 6 of NLP. The classifyer show uses Machine learning, where the user can train the program on its decision making through example. We can improve the givenvgender classfiyer if the pointers supplied leads the machine to the correct choice. The presented issue in the amount of examples the classfiyer has learned leads the program more on target. We decided on the text classfiyer to use the Decision Tree model for our approach, as it can efficently scale down the possibilities of the correct choice dependent on the branch.\n",
    "\n",
    "First, Let's start up the classfiyer and its following model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e2876",
   "metadata": {},
   "source": [
    "#### Gender Identification With A Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462b635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\walki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\names.zip.\n"
     ]
    }
   ],
   "source": [
    "### Initialize a classifier\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "\n",
    "# Download names if they don't exist locally\n",
    "try:\n",
    "    nltk.data.find('corpora/names')\n",
    "except LookupError:\n",
    "    nltk.download('names')\n",
    "    \n",
    "from nltk.corpus import names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebdbdf",
   "metadata": {},
   "source": [
    "### Define Different Features for the Decision Tree Classifiers\n",
    "\n",
    "In order to train our machine to guess the correct gender, we have to incorporate the deciding factors. The machine will take account the exmanied parts of the name and see if there's a strong polarity with a specific feature of the name and gender. For example, the given feature takes the first and last letter of the name for its deiciding feature and the machine make a inference. We could see that there is a strong trend of female names ending with a e. \n",
    "\n",
    "We spilt up the feature deciders into their own functions to limit on what factors may lead the machine to overfit its results. Then, we can display all the created functions with their accuray results compared overall. For our created feature sets: The features 4 and 5 uses parts of us culutral structure for the text analysis. For example, feature 4 has a vowl feature which would return a count of variables used in a name. The program can take this naming feature and make a guess that more feminie names use more vowels than masculine or there is a pattern of a specific vowel count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a43c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from NLTK Chapter 6\n",
    "# Guessing the gender from the last letter of a name\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1] }\n",
    "\n",
    "# Guess the gender from the first/last letter and counting letters\n",
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features['count (%s)' % letter] = name.lower().count(letter)\n",
    "        features['has (%s)' % letter] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "#our attempts at features\n",
    "\n",
    "# Just a predictably bad guesser\n",
    "def bad_feature(word):\n",
    "    return {'bleah' : 1}\n",
    "\n",
    "#Features which take in account specific letters with strong accuray given in the g1 func\n",
    "def gender_features3(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    features['.*arry$'] = re.match(r\".*arry$\", name)\n",
    "    features['.*b[ea]rt$'] = re.match(\".*b[ea]rt$\", name)\n",
    "    features['.*ie$'] = re.match(\".*ie$\", name)\n",
    "    features['Sch'] = re.match(r\"Sch\", name)\n",
    "    features['Pam'] = re.match(r\"Pam\", name)\n",
    "    features['V.*a$'] = re.match(r\"V.*a$\", name)\n",
    "    features['M.*l$'] = re.match(r\"M.*l$\", name) \n",
    "    \n",
    "    return features\n",
    "\n",
    "#features with a count of the number of vowels, letters with softer sounds, ending for re-gender names\n",
    "def gender_features4(name):\n",
    "    features={}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for vowels in 'aeiou':\n",
    "        features['Vowel']=(vowels in name.lower())\n",
    "    features['.*y$']=re.match(r\".*y$\", name)\n",
    "    features['.*ia$']=re.match(r\".*ia$\", name)\n",
    "    features['.*li']=re.match(r\".*li$\", name)\n",
    "    features['.*ck$']=re.match(r\".*ck$\", name)\n",
    "    return features\n",
    "    \n",
    "# create a list of feature function\n",
    "gender_functions = [gender_features, \n",
    "                    gender_features2, \n",
    "                    bad_feature, \n",
    "                    gender_features3,\n",
    "                    gender_features4\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078c540",
   "metadata": {},
   "source": [
    "### Evaulating the feature functions\n",
    "\n",
    "We can now put our created functions up to the test. We compiled three types of name list with a combination of names of all genders inside and divide it up for the training, Dev test and our offical test. We then iterate through our feauture functions through all its features sets and trained our deicison tree with the collection. Then, the classifyer was used to identify the accuracy of its guesses with the collection. \n",
    "\n",
    "All our run produced different rankings, as the randomization of the names can benefit certain feature sets. It is shown the high accuracy the given gender_features2 driven by count. For example, our bad feature set seems to have a idenitical ranking compared to the feature set given from the chapter. This shows that the classiyer can be influence into the wrong guess, as the gender_feature will base it guess all on the last letter than to guess blindly in the bad feature. For our positive scores, Features 4 & 5 holds higher ranking in the dev and test accuracy compared to the others. It can be seen that the classiyer has a higher chance in dev/test accuracy if its training accuracy is already high. However, there are the odds that the training set had more revelant letter for the given feature sets than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9110bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all names into a list\n",
    "all_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "            [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "# randomize the entire list\n",
    "random.shuffle(all_names)\n",
    "\n",
    "\n",
    "# Setup the train, devtest and test sets\n",
    "train_names, devtest_names, test_names = all_names[0:500], all_names[500:1000], all_names[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a233713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Devtest Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_features</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.629608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.745248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad_feature</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.629608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.732143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.734447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Function  Training Accuracy  Devtest Accuracy  Test Accuracy\n",
       "0   gender_features              0.776             0.628       0.629608\n",
       "1  gender_features2              0.956             0.750       0.745248\n",
       "2       bad_feature              0.630             0.628       0.629608\n",
       "3  gender_features3              0.894             0.770       0.732143\n",
       "4  gender_features4              0.924             0.756       0.734447"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the different feature functions \n",
    "# and compare their accuracy\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# For each feature function, try to classify the test sets\n",
    "for fn in gender_functions:\n",
    "    train_set = [(fn(n), g) for (n,g) in train_names]\n",
    "    devtest_set = [(gender_features2(n), g) for (n,g) in devtest_names]\n",
    "    test_set = [(gender_features2(n), g) for (n,g) in test_names]\n",
    "    \n",
    "    # make a classifier from the training set\n",
    "    classifier = nltk.classify.DecisionTreeClassifier.train(train_set)\n",
    "\n",
    "    # Print the classifier logic\n",
    "    #print(classifier)\n",
    "\n",
    "    # Get the accuracies\n",
    "    accuracy_train = nltk.classify.accuracy(classifier, train_set)\n",
    "    accuracy_devtest = nltk.classify.accuracy(classifier, devtest_set)\n",
    "    accuracy_test = nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "    results_list.append([fn.__name__, accuracy_train, accuracy_devtest, accuracy_test])\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list,\n",
    "                          columns=['Function', \n",
    "                                   'Training Accuracy', \n",
    "                                   'Devtest Accuracy',\n",
    "                                   'Test Accuracy',\n",
    "                                   ])\n",
    "\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4e43f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the errors from using the devtest_set\n",
    "#errors = []\n",
    "#for (name, tag) in devtest_names:\n",
    "#    guess = classifier.classify(gender_features(name))\n",
    "#    if guess != tag:\n",
    "#        errors.append( (tag, guess, name) )\n",
    "\n",
    "#for (tag, guess, name) in sorted(errors):\n",
    "#    print( 'correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3815dee",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "The feature functions the machine uses to learn benefits off the relevancy of its training set. The machine has a higher possibility of its accuracy if the supplied features training hits correct branch. As our set was model from the decision tree, its probability is at the high variance. Once the machince travels down a branch of a stronger association with a gender, it cannot transerve onto the the options. So, the feature options that take account cultural relevancy like feminie names like lia or marcelia or masculine names with harsher letters can flip the machines into hard choices. Gender_function2 has a highest test accuracy as its uses non cultural feautres and uses counts to make the assumptions, which allows the machines to pick more freely between branches. The machine can set its choices later in the branches.\n",
    "\n",
    "One item not mentioned in the gender classfication is the set of names used and their variety. We cannot determine if the names used are just names relevant to a certain type of group and this can affect the accuracy when a new group of names are introduce. This can alter the testing results if the training group's names lack diversity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
