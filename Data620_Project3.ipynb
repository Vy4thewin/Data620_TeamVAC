{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcb6db3",
   "metadata": {},
   "source": [
    "# Project 3 Text Analysis with NLTK Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a96f4d6",
   "metadata": {},
   "source": [
    "## By Team VC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8751c7",
   "metadata": {},
   "source": [
    "### Intro into Text Mining "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8b6bf",
   "metadata": {},
   "source": [
    "For project 3, we were given the task to create and improve a classifier that correctly guesses the gender of random names (e.g. Charles, Roberta, Eve) as shown in Chapter 6 of NLP. We trained a decision tree classifier by submitting a 500 name training set and testing it with other names.\n",
    "\n",
    "Some initial functions from the text are included as a benchmark and we know we've improved our gender classifier if it has a higher accuracy rate than the text book classifiers. One noticed issue is the accuracy is directly proportional to the amount of test names. We decided on the text classfiyer to use the Decision Tree model for our approach, as it can efficently scale down the possibilities of the correct choice dependent on the branch.\n",
    "\n",
    "First, Let's start up the classfiyer and its following model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096e2876",
   "metadata": {},
   "source": [
    "#### Gender Identification With A Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462b635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize a classifier\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "\n",
    "# Download names if they don't exist locally\n",
    "try:\n",
    "    nltk.data.find('corpora/names')\n",
    "except LookupError:\n",
    "    nltk.download('names')\n",
    "    \n",
    "from nltk.corpus import names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccebdbdf",
   "metadata": {},
   "source": [
    "### Defining Different Features for the Decision Tree Classifiers\n",
    "\n",
    "In order to train our machine to guess the correct gender, we incorporated the deciding factors. The machine will take account the examined parts of the name and see if there's a strong polarity with a specific feature of the name and gender. For example, the given feature takes the first and last letter of the name for its deiciding feature and the machine make an inference. For example, we could see there is a strong trend of female names ending with an 'e'. \n",
    "\n",
    "We split up the feature deciders into their own functions (gender_features3 & gender_features4) to limit on what factors may lead the machine to overfit its results. Then, we displayed all the created functions with their accuracy results compared overall. For our created feature sets: The gender_features 4 and 3 uses parts of US cultural structure for the text analysis. For example, gender_features4 has a vowel feature which would return a count of variables used in a name. The program can take this naming feature and make a guess that more feminine names use more vowels than masculine ones, or there is a pattern of a specific vowel count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a43c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from NLTK Chapter 6\n",
    "# Guessing the gender from the last letter of a name\n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1] }\n",
    "\n",
    "# Guess the gender from the first/last letter and counting letters\n",
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features['count (%s)' % letter] = name.lower().count(letter)\n",
    "        features['has (%s)' % letter] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "#our attempts at features\n",
    "\n",
    "# Just a predictably bad guesser\n",
    "def bad_feature(word):\n",
    "    return {'bleah' : 1}\n",
    "\n",
    "#Features which take in account specific letters with strong accuray given in the g1 func\n",
    "def gender_features3(name):\n",
    "    features = {}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    features['.*arry$'] = re.match(r\".*arry$\", name)\n",
    "    features['.*b[ea]rt$'] = re.match(\".*b[ea]rt$\", name)\n",
    "    features['.*ie$'] = re.match(\".*ie$\", name)\n",
    "    features['Sch'] = re.match(r\"Sch\", name)\n",
    "    features['Pam'] = re.match(r\"Pam\", name)\n",
    "    features['V.*a$'] = re.match(r\"V.*a$\", name)\n",
    "    features['M.*l$'] = re.match(r\"M.*l$\", name) \n",
    "    \n",
    "    return features\n",
    "\n",
    "#features with a count of the number of vowels, letters with softer sounds, ending for re-gender names\n",
    "def gender_features4(name):\n",
    "    features={}\n",
    "    features['firstletter'] = name[0].lower()\n",
    "    features['lastletter'] = name[-1].lower()\n",
    "    for vowels in 'aeiou':\n",
    "        features['Vowel']=(vowels in name.lower())\n",
    "    features['.*y$']=re.match(r\".*y$\", name)\n",
    "    features['.*ia$']=re.match(r\".*ia$\", name)\n",
    "    features['.*li']=re.match(r\".*li$\", name)\n",
    "    features['.*ck$']=re.match(r\".*ck$\", name)\n",
    "    return features\n",
    "    \n",
    "# create a list of feature function to test\n",
    "gender_functions = [gender_features, \n",
    "                    gender_features2, \n",
    "                    bad_feature, \n",
    "                    gender_features3,\n",
    "                    gender_features4\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078c540",
   "metadata": {},
   "source": [
    "### Evaulating the feature functions\n",
    "\n",
    "We can now put our created functions up to the test. We compiled three types of name lists with a random combination of names of all genders inside and divided it up into three sets:\n",
    "  * 500 name training set\n",
    "  * 500 name development-test set\n",
    "  * 6500 name official test sets\n",
    "  \n",
    "We then iterated through our feauture functions through all its features sets and trained our decison trees with the collection. Then, the classifier was used to identify the accuracy of its guesses with the collection. \n",
    "\n",
    "All our runs produced different rankings, as the randomization of the names can benefit certain feature sets. It is shown the high accuracy the given gender_features2 driven by count. For example, our bad feature set seems to have a identical ranking compared to the feature set given from the chapter. This shows  the classifier can be influenced into wrong guesses, as the gender_feature will base its guess all on the last letter than to guess blindly in the bad feature. \n",
    "\n",
    "For our positive scores, Features 4 & 3 holds higher ranking in the dev and test accuracy compared to the others. It can be seen  the classifier has a higher chance in dev/test accuracy if its training accuracy is already high. However, there are the odds that the training set had more revelant letter for the given feature sets than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9110bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all names into a list\n",
    "all_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "            [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "# randomize the entire list\n",
    "random.shuffle(all_names)\n",
    "\n",
    "\n",
    "# Setup the train, devtest and test sets\n",
    "train_names, devtest_names, test_names = all_names[0:500], all_names[500:1000], all_names[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a233713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Devtest Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender_features</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.369240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.743664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad_feature</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.630760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.755616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.759217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Function  Training Accuracy  Devtest Accuracy  Test Accuracy\n",
       "0   gender_features              0.780             0.366       0.369240\n",
       "1  gender_features2              0.962             0.720       0.743664\n",
       "2       bad_feature              0.608             0.634       0.630760\n",
       "3  gender_features3              0.872             0.758       0.755616\n",
       "4  gender_features4              0.900             0.754       0.759217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the different feature functions \n",
    "# and compare their accuracy\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# For each feature function, try to classify the test sets\n",
    "for fn in gender_functions:\n",
    "    train_set = [(fn(n), g) for (n,g) in train_names]\n",
    "    devtest_set = [(gender_features2(n), g) for (n,g) in devtest_names]\n",
    "    test_set = [(gender_features2(n), g) for (n,g) in test_names]\n",
    "    \n",
    "    # make a classifier from the training set\n",
    "    classifier = nltk.classify.DecisionTreeClassifier.train(train_set)\n",
    "\n",
    "    # Print the classifier logic\n",
    "    #print(classifier)\n",
    "\n",
    "    # Get the accuracies\n",
    "    accuracy_train = nltk.classify.accuracy(classifier, train_set)\n",
    "    accuracy_devtest = nltk.classify.accuracy(classifier, devtest_set)\n",
    "    accuracy_test = nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "    results_list.append([fn.__name__, accuracy_train, accuracy_devtest, accuracy_test])\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results_list,\n",
    "                          columns=['Function', \n",
    "                                   'Training Accuracy', \n",
    "                                   'Devtest Accuracy',\n",
    "                                   'Test Accuracy',\n",
    "                                   ])\n",
    "\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4e43f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional code to detail incorrect guesses\n",
    "# \n",
    "#errors = []\n",
    "#for (name, tag) in devtest_names:\n",
    "#    guess = classifier.classify(gender_features(name))\n",
    "#    if guess != tag:\n",
    "#        errors.append( (tag, guess, name) )\n",
    "\n",
    "#for (tag, guess, name) in sorted(errors):\n",
    "#    print( 'correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3815dee",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "The feature functions the machine uses to learn benefits off the relevancy of its training set. The machine has a higher possibility accuracy if the supplied features training hits correct branches. As our set was modeled from the decision tree, its probability is at the high variance. Once the machine travels down a branch of a stronger association with a gender, it cannot traverse onto the other options. \n",
    "\n",
    "So, the feature options that take account cultural relevancy like feminine names like lia or marcelia or masculine names with harsher letters can flip the machines into hard choices. Gender_features2 has a highest test accuracy as its uses non-cultural features and uses counts to make the assumptions, which allows the machines to pick more freely between branches. The machine can set its choices later in the branches.\n",
    "\n",
    "One item not mentioned in the gender classfication is the set of names used and their variety. We cannot determine if the names used are just names relevant to a certain type of group and this can affect the accuracy when a new group of names are introduce. This can alter the testing results if the training group's names lack diversity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
